{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#custom\n",
    "import utils\n",
    "import plots\n",
    "import transformers as tran\n",
    "\n",
    "LABEL = \"1Y_default\"\n",
    "SEED = 42\n",
    "\n",
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data from csv\n",
    "data_full = pd.read_csv(\"LoanData.csv\")\n",
    "\n",
    "print(\"Raw data shape: {}\".format(data_full.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preselect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select only relevant variables available at application\n",
    "to_keep = [\"LoanDate\",\"DefaultDate\", \"Age\", \"ProbabilityOfDefault\", \"Amount\", \"AmountOfPreviousLoansBeforeLoan\", \"AppliedAmount\", \"City\", \"Country\", \"County\", \"DebtToIncome\",\n",
    "           \"Education\", \"EmploymentDurationCurrentEmployer\", \"EmploymentPosition\", \"EmploymentStatus\",\n",
    "           \"ExistingLiabilities\", \"FreeCash\", \"Gender\", \"HomeOwnershipType\", \"IncomeFromChildSupport\", \"IncomeFromFamilyAllowance\",\n",
    "           \"IncomeFromLeavePay\", \"IncomeFromPension\", \"IncomeFromPrincipalEmployer\", \"IncomeFromSocialWelfare\", \n",
    "           \"IncomeOther\", \"IncomeTotal\", \"Interest\", \"LanguageCode\", \"MaritalStatus\", \"MonthlyPayment\", \"NewCreditCustomer\",\n",
    "           \"NoOfPreviousLoansBeforeLoan\", \"NrOfDependants\", \"OccupationArea\", \"UseOfLoan\", \"VerificationType\", \"WorkExperience\"   \n",
    "]\n",
    "\n",
    "data_df = data_full[to_keep]\n",
    "print(\"Data shape: {}\".format(data_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create label (1Y default flag) based on default day\n",
    "#convert to date\n",
    "data_df[\"DefaultDate\"] =pd.to_datetime(data_df[\"DefaultDate\"], yearfirst=True)\n",
    "data_df[\"LoanDate\"] = pd.to_datetime(data_df[\"LoanDate\"], yearfirst=True)\n",
    "\n",
    "#days between start and default\n",
    "data_df[\"default_delta\"] = (data_df[\"DefaultDate\"].values - data_df[\"LoanDate\"].values)\n",
    "\n",
    "def date_to_int(date):\n",
    "    try:\n",
    "        return date.days\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "data_df[\"default_delta\"] = data_df[\"default_delta\"].apply(date_to_int)\n",
    "#default flag\n",
    "data_df[\"1Y_default\"] = (data_df[\"default_delta\"].values <= 365)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select only loans originated during years 2013-2017\n",
    "data_df[\"OriginYear\"] = data_df[\"LoanDate\"].apply(lambda date: date.year)\n",
    "#select only loans where 1Y default is known\n",
    "data_df = data_df[data_df[\"LoanDate\"] < pd.Timestamp('2017-06-01 00:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plots.dependence_cat(data_df[LABEL], data_df[\"OriginYear\"], estimator=np.mean, y_label=\"Average deafult rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plots.dependence_cat(data_df[\"ProbabilityOfDefault\"], data_df[\"OriginYear\"], estimator=np.mean, y_label=\"Average predicted PD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select only years 2014+\n",
    "data_df = data_df[data_df[\"LoanDate\"] < pd.Timestamp('2017-06-01 00:00:00')]\n",
    "\n",
    "#drop unwanted columns\n",
    "data_filtered_df = data_df.drop([\"LoanDate\", \"DefaultDate\", \"ProbabilityOfDefault\", \"default_delta\", \"OriginYear\"], axis=1)\n",
    "print(\"Filtered data shape: {}\".format(data_filtered_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop City, County, EmploymentPosition: too high cardinality with only few observations\n",
    "data_filtered_df = data_filtered_df.drop([\"City\", \"County\", \"EmploymentPosition\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some features has missing values as well as special category (0 or -1) for missing\n",
    "to_correct = [\"Education\", \"MaritalStatus\", \"VerificationType\"]\n",
    "for feature in to_correct:\n",
    "    data_filtered_df[feature].replace(0, np.nan, inplace=True)\n",
    "\n",
    "data_filtered_df[\"OccupationArea\"].replace(-1, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check for dtypes\n",
    "data_filtered_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#correct dtypes:\n",
    "#correct NrOfDependants\n",
    "def correct_dependants(row):\n",
    "    try:\n",
    "        return int(row)\n",
    "    except:\n",
    "        return row\n",
    "    \n",
    "data_filtered_df[\"NrOfDependants\"] = data_filtered_df[\"NrOfDependants\"].apply(correct_dependants)\n",
    "\n",
    "#numerically encoded categoricals\n",
    "to_categorical = [\"Education\", \"EmploymentStatus\", \"Gender\", \"HomeOwnershipType\", \"LanguageCode\", \"MaritalStatus\",\n",
    "                 \"NewCreditCustomer\", \"OccupationArea\", \"UseOfLoan\", \"VerificationType\", \"Country\", \"NrOfDependants\", \n",
    "                  \"NrOfDependants\", \"WorkExperience\", \"EmploymentDurationCurrentEmployer\"]\n",
    "for feature in to_categorical:\n",
    "    data_filtered_df[feature] = data_filtered_df[feature].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filtered_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check missings\n",
    "utils.check_missing(data_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#discretize and create new category for missing\n",
    "data_filtered_df[\"MonthlyPayment\"] = data_filtered_df[\"MonthlyPayment\"].apply(utils.make_bins, tresholds=[100])\n",
    "data_filtered_df[\"MonthlyPayment\"] = data_filtered_df[\"MonthlyPayment\"].astype(\"category\")\n",
    "plots.dependence_cat(data_filtered_df[LABEL] , data_filtered_df[\"MonthlyPayment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create new category for missing\n",
    "data_filtered_df[\"HomeOwnershipType\"] = data_filtered_df[\"HomeOwnershipType\"].cat.add_categories([\"N/A\"])\n",
    "data_filtered_df[\"HomeOwnershipType\"].fillna(\"N/A\", inplace=True)\n",
    "plots.dependence_cat(data_filtered_df[LABEL] , data_filtered_df[\"HomeOwnershipType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#discretize, fill nan later with other features\n",
    "data_filtered_df[\"NrOfDependants\"] = data_filtered_df[\"NrOfDependants\"].cat.add_categories([\"3+\"])\n",
    "data_filtered_df[\"NrOfDependants\"] = data_filtered_df[\"NrOfDependants\"].replace([\"10Plus\", 10,9,8,7,6,5,4,3], \"3+\")\n",
    "data_filtered_df[\"NrOfDependants\"] = data_filtered_df[\"NrOfDependants\"].cat.remove_unused_categories()\n",
    "data_filtered_df[\"NrOfDependants\"] = data_filtered_df[\"NrOfDependants\"]\n",
    "plots.dependence_cat(data_filtered_df[LABEL] , data_filtered_df[\"NrOfDependants\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill nans, median for continuous, mode for categoricals\n",
    "filler = tran.NaN_filler()\n",
    "data_df = filler.fit_transform(data_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check to be sure\n",
    "utils.check_missing(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stratified split before feature selection\n",
    "train_df, test_df = utils.stratified_train_test_split(data_df, LABEL, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export both sets before further analysis and selection\n",
    "train_df.to_csv(\"train_full.csv\", index=False)\n",
    "test_df.to_csv(\"test_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sort predictors by in-sample univariate score (using logistic regression)\n",
    "scores = utils.get_univariate_ginis(train_df, LABEL, model=\"logit\", random_state=SEED)\n",
    "scores.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#work with selected features only\n",
    "train_df = train_df[list(scores.head(15).index)+[LABEL]]\n",
    "test_df = test_df[list(scores.head(15).index)+[LABEL]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coarse classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Language code\n",
    "#drop feature Country contains almost the same information in better format\n",
    "plots.dependence_cat(train_df[LABEL] , train_df[\"LanguageCode\"])\n",
    "train_df.drop(\"LanguageCode\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Country\n",
    "#merge SK (too few observations) to ES\n",
    "plots.dependence_cat(train_df[LABEL] , train_df[\"Country\"])\n",
    "\n",
    "country_map = {\"SK\" : \"ES\"}\n",
    "train_df[\"Country\"] = train_df[\"Country\"].replace(country_map)\n",
    "plots.dependence_cat(train_df[LABEL] , train_df[\"Country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Home ownership\n",
    "plots.dependence_cat(train_df[LABEL] , train_df[\"HomeOwnershipType\"])\n",
    "\n",
    "#obviosly \"overfitted\"\n",
    "def merge_home(row):\n",
    "    if row in [7,8,9]:\n",
    "        return \"789\"\n",
    "    elif row in [2,3,4,0]:\n",
    "        return \"234\"\n",
    "    elif row in [5,6]:\n",
    "        return \"56\"\n",
    "    else:\n",
    "        return row\n",
    "train_df[\"HomeOwnershipType\"] = train_df[\"HomeOwnershipType\"].apply(merge_home)\n",
    "train_df[\"HomeOwnershipType\"] = train_df[\"HomeOwnershipType\"].astype(\"category\")\n",
    "plots.dependence_cat(train_df[LABEL], train_df[\"HomeOwnershipType\"])\n",
    "score = utils.get_univariate_ginis(train_df[[\"HomeOwnershipType\", LABEL]], LABEL, random_state=SEED)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Marital status\n",
    "plots.dependence_cat(train_df[LABEL], train_df[\"MaritalStatus\"])\n",
    "#merge \"divorced\" (4) and \"widowed\" (5)\n",
    "def merge_marital(row):\n",
    "    if row in [4, 5]:\n",
    "        return 45\n",
    "    else:\n",
    "        return row\n",
    "train_df[\"MaritalStatus\"] = train_df[\"MaritalStatus\"].apply(merge_marital)\n",
    "plots.dependence_cat(train_df[LABEL], train_df[\"MaritalStatus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OccupationArea\n",
    "plots.dependence_cat(train_df[LABEL], train_df[\"OccupationArea\"], figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_occupation(row):\n",
    "    if row == 16:\n",
    "        return \"very low\"\n",
    "    if row in [3, 7, 10, 11, 13, 15, 18, 19]:\n",
    "        return \"low\"\n",
    "    if row in [1, 2, 4, 6, 8, 12, 14, 17]:\n",
    "        return \"medium\"\n",
    "    if row in [0, 5, 9]:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "train_df[\"OccupationArea\"] = train_df[\"OccupationArea\"].apply(merge_occupation)\n",
    "plots.dependence_cat(train_df[LABEL], train_df[\"OccupationArea\"])\n",
    "score = utils.get_univariate_ginis(train_df[[\"OccupationArea\", LABEL]], LABEL, random_state=SEED)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#UseOfLoan\n",
    "#all 1xx to business (3) business logic\n",
    "def merge_business(row):\n",
    "    if row in [101, 102, 103, 104, 105, 106, 107, 108, 109, 110]:\n",
    "        return 3\n",
    "    else:\n",
    "        return row\n",
    "    \n",
    "train_df[\"UseOfLoan\"] = train_df[\"UseOfLoan\"].apply(merge_business)\n",
    "plots.dependence_cat(train_df[LABEL], train_df[\"UseOfLoan\"], figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_use(row):\n",
    "    if row in [4, 7, 8]:\n",
    "        return \"high\"\n",
    "    if row in [1 , 2, 3, 5, 6]:\n",
    "        return \"medium\"\n",
    "    if row == 0:\n",
    "        return \"low\"\n",
    "    else:\n",
    "        return row\n",
    "    \n",
    "train_df[\"UseOfLoan\"] = train_df[\"UseOfLoan\"].apply(merge_use)\n",
    "plots.dependence_cat(train_df[LABEL], train_df[\"UseOfLoan\"])\n",
    "score = utils.get_univariate_ginis(train_df[[\"UseOfLoan\", LABEL]], LABEL, random_state=SEED)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply same transformations to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.drop(\"LanguageCode\", axis=1, inplace=True)\n",
    "test_df[\"Country\"] = test_df[\"Country\"].replace(country_map)\n",
    "test_df[\"HomeOwnershipType\"] = test_df[\"HomeOwnershipType\"].apply(merge_home)\n",
    "test_df[\"MaritalStatus\"] = test_df[\"MaritalStatus\"].apply(merge_marital)\n",
    "test_df[\"OccupationArea\"] = test_df[\"OccupationArea\"].apply(merge_occupation)\n",
    "test_df[\"UseOfLoan\"] = test_df[\"UseOfLoan\"].apply(merge_business)\n",
    "test_df[\"UseOfLoan\"] = test_df[\"UseOfLoan\"].apply(merge_use)\n",
    "\n",
    "#correct dtypes\n",
    "feats = [\"Country\", \"HomeOwnershipType\", \"MaritalStatus\", \"OccupationArea\", \"UseOfLoan\"]\n",
    "for feat in feats:\n",
    "    train_df[feat] = train_df[feat].astype(\"category\")\n",
    "    train_df[feat] = train_df[feat].cat.remove_unused_categories()\n",
    "    test_df[feat] = test_df[feat].astype(\"category\")\n",
    "    test_df[feat] = test_df[feat].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairwise correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#woe-encode categoricals\n",
    "woe = tran.WoE_transformer()\n",
    "train_woe_df = woe.fit_transform(train_df, train_df[LABEL])\n",
    "\n",
    "plots.plot_correlation_matrix(train_woe_df.drop(LABEL, axis=1), figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#eliminate correlations >60% => NoOfPreviousLoansBeforeLoan, AmountOfPreviousLoansBeforeLoan, NewCreditCustomer\n",
    "#keep NewCreditCustomer, simplest, ginis almost the same\n",
    "train_df.drop(\"NoOfPreviousLoansBeforeLoan\", axis=1, inplace=True)\n",
    "test_df.drop(\"NoOfPreviousLoansBeforeLoan\", axis=1, inplace=True)\n",
    "train_df.drop(\"AmountOfPreviousLoansBeforeLoan\", axis=1, inplace=True)\n",
    "test_df.drop(\"AmountOfPreviousLoansBeforeLoan\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest relative feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ohe-encode categoricals\n",
    "ohe = tran.OHE_transformer()\n",
    "X = ohe.fit_transform(train_df.drop(LABEL, axis=1))\n",
    "y = train_df[LABEL]\n",
    "#fit rf\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X.values, y.values)\n",
    "#plot importances\n",
    "plots.FeaturesImportanceTree(rf, X.columns, head=None, figsize=(11, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export both sets after selection\n",
    "train_df.to_csv(\"train_selected.csv\", index=False)\n",
    "test_df.to_csv(\"test_selected.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
